{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import scipy.interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "import sys\n",
    "import logging\n",
    "import glob\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "sys.path.append('../src/')\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from cnn.simulator import Simulator\n",
    "\n",
    "from cnn.models import ConvNet\n",
    "from cnn.losses import CustomLoss\n",
    "from cnn.callbacks import SaveModelWeightsCallback\n",
    "\n",
    "from cnn.metrics import CustomAUC\n",
    "from cnn.metrics import CustomMREArea\n",
    "from cnn.metrics import CustomMAELoc\n",
    "from cnn.metrics import get_accuracy_metrics_at_thresholds\n",
    "\n",
    "from cnn.preprocessing import LabelEncoder\n",
    "from cnn.data_generators import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Model training\n",
    "NUM_TRAIN_EXAMPLES = int(1e6)\n",
    "NUM_TEST_EXAMPLES = int(1e4)\n",
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = 1e5 // BATCH_SIZE\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Model optimizer\n",
    "INITIAL_LEARNING_RATE = 1e-3\n",
    "END_LEARNING_RATE = 1e-5\n",
    "DECAY_STEPS = int(STEPS_PER_EPOCH / BATCH_SIZE * NUM_EPOCHS)\n",
    "\n",
    "# Label encoder\n",
    "NUM_CLASSES = 3\n",
    "NUM_WINDOWS = 256\n",
    "INPUT_SIZE = 8192\n",
    "\n",
    "# Define loss function, optimizer and metrics\n",
    "loss_fn = CustomLoss(\n",
    "    n_splits=NUM_CLASSES, \n",
    "    weight_prob=1.0, \n",
    "    weight_loc=1.0, \n",
    "    weight_area=1.0\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "        initial_learning_rate=INITIAL_LEARNING_RATE, \n",
    "        decay_steps=DECAY_STEPS, \n",
    "        end_learning_rate=END_LEARNING_RATE\n",
    "    )\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    CustomMREArea(name='mre_area'),\n",
    "    CustomMAELoc(name='mae_loc'),\n",
    "    CustomAUC(name='prob_auc'),\n",
    "]\n",
    "\n",
    "# Define data generators \n",
    "# Simulator uses method of label_encoder to deal with collisions\n",
    "label_encoder = LabelEncoder(NUM_WINDOWS)\n",
    "train_generator = DataGenerator(\n",
    "    indices=np.arange(0, NUM_TRAIN_EXAMPLES), \n",
    "    simulator=Simulator(\n",
    "        label_encoder.remove_collision, \n",
    "        resolution=INPUT_SIZE, \n",
    "        white_noise_prob=1.0), \n",
    "    label_encoder=label_encoder,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = DataGenerator(\n",
    "    indices=np.arange(NUM_TRAIN_EXAMPLES, NUM_TRAIN_EXAMPLES + NUM_TEST_EXAMPLES), \n",
    "    simulator=Simulator(\n",
    "        label_encoder.remove_collision, \n",
    "        resolution=INPUT_SIZE, \n",
    "        white_noise_prob=1.0), \n",
    "    label_encoder=label_encoder,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "model = ConvNet(\n",
    "    filters=[64, 128, 128, 256, 256],\n",
    "    kernel_sizes=[9, 9, 9, 9, 9],\n",
    "    dropout=0.0,\n",
    "    pool_type='max',\n",
    "    pool_sizes=[2, 2, 2, 2, 2],\n",
    "    conv_block_size=1,\n",
    "    input_shape=(INPUT_SIZE, 1),\n",
    "    output_shape=(NUM_WINDOWS, NUM_CLASSES),\n",
    "    residual=False\n",
    ")\n",
    "\n",
    "model.compile(loss=loss_fn, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "# Weights will be saved each epoch to outputs/weights/weight_{epoch:03d}.h5\n",
    "model.fit(\n",
    "    train_generator, validation_data=test_generator,\n",
    "    epochs=NUM_EPOCHS, steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    callbacks=[SaveModelWeightsCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
